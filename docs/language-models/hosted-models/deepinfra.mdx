---
title: DeepInfra
---

To use Probe with DeepInfra, set the `model` flag:

<CodeGroup>

```bash Terminal
probe --model deepinfra/<deepinfra-model>
```

```python Python
from probe import probe

probe.llm.model = "deepinfra/<deepinfra-model>"
probe.chat()
```

</CodeGroup>

# Supported Models

We support the following completion models from DeepInfra:

- Llama-2 70b chat hf
- Llama-2 7b chat hf
- Llama-2 13b chat hf
- CodeLlama 34b instruct awq
- Mistral 7b instruct v0.1
- jondurbin/airoboros I2 70b gpt3 1.4.1

<CodeGroup>

```bash Terminal
probe --model deepinfra/meta-llama/Llama-2-70b-chat-hf
probe --model deepinfra/meta-llama/Llama-2-7b-chat-hf
probe --model deepinfra/meta-llama/Llama-2-13b-chat-hf
probe --model deepinfra/codellama/CodeLlama-34b-Instruct-hf
probe --model deepinfra/mistral/mistral-7b-instruct-v0.1
probe --model deepinfra/jondurbin/airoboros-l2-70b-gpt4-1.4.1
```

```python Python
probe.llm.model = "deepinfra/meta-llama/Llama-2-70b-chat-hf"
probe.llm.model = "deepinfra/meta-llama/Llama-2-7b-chat-hf"
probe.llm.model = "deepinfra/meta-llama/Llama-2-13b-chat-hf"
probe.llm.model = "deepinfra/codellama/CodeLlama-34b-Instruct-hf"
probe.llm.model = "deepinfra/mistral-7b-instruct-v0.1"
probe.llm.model = "deepinfra/jondurbin/airoboros-l2-70b-gpt4-1.4.1"
```

</CodeGroup>

# Required Environment Variables

Set the following environment variables [(click here to learn how)](https://chat.openai.com/share/1062cdd8-62a1-4aa8-8ec9-eca45645971a) to use these models.

| Environment Variable | Description       | Where to Find                                                          |
| -------------------- | ----------------- | ---------------------------------------------------------------------- |
| `DEEPINFRA_API_KEY` | DeepInfra API key | [DeepInfra Dashboard -> API Keys](https://deepinfra.com/dash/api_keys) |
