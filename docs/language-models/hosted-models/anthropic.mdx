---
title: Anthropic
---

To use Probe with a model from Anthropic, set the `model` flag:

<CodeGroup>

```bash Terminal
probe --model claude-instant-1
```

```python Python
from probe import probe

probe.llm.model = "claude-instant-1"
probe.chat()
```

</CodeGroup>

# Supported Models

We support any model from [Anthropic:](https://www.anthropic.com/)

<CodeGroup>

```bash Terminal
probe --model claude-instant-1
probe --model claude-instant-1.2
probe --model claude-2
```

```python Python
probe.llm.model = "claude-instant-1"
probe.llm.model = "claude-instant-1.2"
probe.llm.model = "claude-2"
```

</CodeGroup>

# Required Environment Variables

Set the following environment variables [(click here to learn how)](https://chat.openai.com/share/1062cdd8-62a1-4aa8-8ec9-eca45645971a) to use these models.

| Environment Variable  | Description  | Where to Find  |
| --------------------- | ------------ | -------------- |
| `ANTHROPIC_API_KEY`       | The API key for authenticating to Anthropic's services. | [Anthropic](https://www.anthropic.com/) |