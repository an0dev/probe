---
title: Cohere
---

To use Probe with a model from Cohere, set the `model` flag:

<CodeGroup>

```bash Terminal
probe --model command-nightly
```

```python Python
from probe import probe

probe.llm.model = "command-nightly"
probe.chat()
```

</CodeGroup>

# Supported Models

We support any model on [Cohere's models page:](https://www.cohere.ai/models)

<CodeGroup>

```bash Terminal
probe --model command
probe --model command-light
probe --model command-medium
probe --model command-medium-beta
probe --model command-xlarge-beta
probe --model command-nightly
```

```python Python
probe.llm.model = "command"
probe.llm.model = "command-light"
probe.llm.model = "command-medium"
probe.llm.model = "command-medium-beta"
probe.llm.model = "command-xlarge-beta"
probe.llm.model = "command-nightly"
```

</CodeGroup>

# Required Environment Variables

Set the following environment variables [(click here to learn how)](https://chat.openai.com/share/1062cdd8-62a1-4aa8-8ec9-eca45645971a) to use these models.

| Environment Variable  | Description  | Where to Find  |
| --------------------- | ------------ | -------------- |
| `COHERE_API_KEY`       | The API key for authenticating to Cohere's services. | [Cohere Account Page](https://app.cohere.ai/login) |