---
title: Baseten
---

To use Probe with Baseten, set the `model` flag:

<CodeGroup>

```bash Terminal
probe --model baseten/<baseten-model>
```

```python Python
from probe import probe

probe.llm.model = "baseten/<baseten-model>"
probe.chat()
```

</CodeGroup>

# Supported Models

We support the following completion models from Baseten:

- Falcon 7b (qvv0xeq)
- Wizard LM (q841o8w)
- MPT 7b Base (31dxrj3)

<CodeGroup>

```bash Terminal
probe --model baseten/qvv0xeq
probe --model baseten/q841o8w
probe --model baseten/31dxrj3
```

```python Python
probe.llm.model = "baseten/qvv0xeq"
probe.llm.model = "baseten/q841o8w"
probe.llm.model = "baseten/31dxrj3"
```

</CodeGroup>

# Required Environment Variables

Set the following environment variables [(click here to learn how)](https://chat.openai.com/share/1062cdd8-62a1-4aa8-8ec9-eca45645971a) to use these models.

| Environment Variable | Description     | Where to Find                                                                                            |
| -------------------- | --------------- | -------------------------------------------------------------------------------------------------------- |
| `BASETEN_API_KEY`    | Baseten API key | [Baseten Dashboard -> Settings -> Account -> API Keys](https://app.baseten.co/settings/account/api_keys) |
